{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BxbeO5YarIc_",
        "LLWkfXmDsE_j"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ex3yOUUTphcj"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "myb__nV3prz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "hqXyL2agpwz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "APqj1DHmpzIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "1I4JR8VSp1KX",
        "outputId": "77774baf-6226-4479-ca3f-94b8035f4f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "QWTH10z8p6Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Emotion Experiments"
      ],
      "metadata": {
        "id": "L3EMz0veN0Uj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Emotion Experiment Design:\n",
        "\n",
        "Step 1: Run a pilot study on the general capability of the most advanced language models / vision-language models to understand whether they are already perfect in their capabilities (Completed)\n",
        "\n",
        "To-Do:\n",
        "Step 2: Design multimodal prompts in multiple ways.\n",
        "  1. Simple questions in prompts - this is the way in which following examples are done. Eg., asking models about whether they understand about emotions expressed in images of facial expressions.\n",
        "  2. Designing Conversational prompts - Asking the model about different parts of the image dataset and then finally asking about an emotion inference.\n",
        "  3. Designing Chain-of-Thought Prompts - asking the model about an emotion inference, where the model also uses chain-of-thought reasoning to arrive at the inference.\n",
        "  4. Generating explanations: For all emotion inference generated, ask for a corresponding explanation.\n",
        "  5. Prompting with and without a sample class space: Asking models about emotional responses with and without a set of ground truth classes to find default granularity.\n",
        "\n",
        "Step 3: Applying all of these prompting techniques to both expressed and evoked emotions and tallying the results for each of the prompting methods.\n",
        "\n",
        "#### Datasets to be used (in addition to the pilot dataset):\n",
        "\n",
        "1. EMOTIC Dataset: https://paperswithcode.com/dataset/emotic\n",
        "2. EmoSet Dataset: https://vcc.tech/EmoSet\n",
        "3. The ArtPhoto Dataset\n",
        "4. The AbstractArt Dataset\n",
        "5. Emotion6 Dataset\n",
        "\n",
        "Possible Extensions: carrying out the same for emotional video understanding."
      ],
      "metadata": {
        "id": "eOqCRp2z61mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image"
      ],
      "metadata": {
        "id": "JfdKjM7kRX4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vision_model = genai.GenerativeModel('gemini-pro-vision')"
      ],
      "metadata": {
        "id": "tg9hWNSpN28f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiments in recognizing human faces\n",
        "\n",
        " Using a small subset of images from a Facial expression recognition dataset: https://www.kaggle.com/datasets/jonathanoheix/face-expression-recognition-dataset?resource=download\n",
        " All images are from the training set, and the respective emotion categories."
      ],
      "metadata": {
        "id": "Ej40C94SPfvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# case 1: Happiness (easy)\n",
        "happiness_easy = \"emotion_face_images/happy/82.jpg\"\n",
        "img = PIL.Image.open(happiness_easy)\n",
        "response1 = vision_model.generate_content([\"What is the emotion expressed in the given picture?\", img], stream = True)"
      ],
      "metadata": {
        "id": "RK9VvQd-PcBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response1.resolve()"
      ],
      "metadata": {
        "id": "yJPMkmYOR6qV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response1.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "ye_Mj9DZRiec",
        "outputId": "66eeaa9e-15c2-420f-e374-6dbf4aa98cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">  The emotion expressed in the given picture is happiness."
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: Identifies happiness easily from pictures that are clearly depictive of it."
      ],
      "metadata": {
        "id": "DTdCKYvJSFRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# case 2: Happiness (difficult)\n",
        "happiness_difficult = \"emotion_face_images/happy/239.jpg\"\n",
        "img = PIL.Image.open(happiness_difficult)\n",
        "response2 = vision_model.generate_content([\"What is the emotion expressed in the given picture?\", img], stream = True)"
      ],
      "metadata": {
        "id": "2AlmdVOvRzOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response2.resolve()"
      ],
      "metadata": {
        "id": "nM0ImKnXS8Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response2.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "IeSKKzM4S91c",
        "outputId": "a2eba7ef-37bf-4a27-f1fa-a7e0cb820c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">  The emotion expressed in the picture is sadness."
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: Misclassifies ambiguous examples, or examples that do not have clear identifiers of an emotion."
      ],
      "metadata": {
        "id": "c1PgmPfITA1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# case 3: Happiness (moderate)\n",
        "happiness_moderate = \"emotion_face_images/happy/1550.jpg\"\n",
        "img = PIL.Image.open(happiness_moderate)\n",
        "response3 = vision_model.generate_content([\"What is the emotion expressed in the given picture?\", img], stream = True)"
      ],
      "metadata": {
        "id": "LE-fJZRBS_V2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response3.resolve()"
      ],
      "metadata": {
        "id": "xfcKY0xXT4G3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response3.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "IcuW-2epT6M9",
        "outputId": "f8bb9b0f-1325-4868-f61f-dc935eb34194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">  The emotion expressed in the given picture is happiness."
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: Is able to classify moderately ambiguous examples."
      ],
      "metadata": {
        "id": "sR7Tx5fhT9jC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# case 4: another moderate example: Happiness (moderate)\n",
        "happiness_moderate2 = \"emotion_face_images/happy/2733.jpg\"\n",
        "img = PIL.Image.open(happiness_moderate2)\n",
        "response4 = vision_model.generate_content([\"What is the emotion expressed in the given picture?\", img], stream = True)"
      ],
      "metadata": {
        "id": "AykKST9nT8i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response4.resolve()"
      ],
      "metadata": {
        "id": "D4oHB0BjUZqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response4.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "uXKim93LUb64",
        "outputId": "d4c7675f-9090-4e67-b5a5-59ef6ca919c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">  The emotion expressed in the picture is happiness."
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: able to classify moderately difficult images"
      ],
      "metadata": {
        "id": "rlIAeeUEUe5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparing *surprise* and *fear*"
      ],
      "metadata": {
        "id": "NemlqbQDUopq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# case 5: Surprise (positive)\n",
        "surprise_p = \"emotion_face_images/surprise/1552.jpg\"\n",
        "img = PIL.Image.open(surprise_p)\n",
        "response5 = vision_model.generate_content([\"What is the emotion expressed in the given picture?\", img], stream = True)"
      ],
      "metadata": {
        "id": "mO0ObVKMUd0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response5.resolve()"
      ],
      "metadata": {
        "id": "JVKoQBKmVIxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response5.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "fE2p8BpaVKNj",
        "outputId": "7d9b290e-c651-4731-d0c3-8308ae494cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">  The emotion expressed in the picture is happiness."
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: Takes the cue of the more basic emotion, instead of classifying surprise."
      ],
      "metadata": {
        "id": "oHz3Tz_HVPQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# case 6: Surprise (negative)\n",
        "surprise_n = \"emotion_face_images/surprise/964.jpg\"\n",
        "img = PIL.Image.open(surprise_n)\n",
        "response6 = vision_model.generate_content([\"What is the emotion expressed in the given picture?\", img], stream = True)"
      ],
      "metadata": {
        "id": "Q2-wuB1BVMNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response6.resolve()"
      ],
      "metadata": {
        "id": "dI3qaqKcVwHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response6.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "GjHxkbsBVxI-",
        "outputId": "529eebdb-1534-492d-e371-9ed536d6df23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">  The emotion expressed in the given picture is fear."
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: classifies negative surprise as fear. Can be considered logically okay as well, because it is zero-shot evaluation."
      ],
      "metadata": {
        "id": "9wUgR5ecV0JE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# case 7: Actual Fear (easy)\n",
        "fear_easy = \"emotion_face_images/fear/669.jpg\"\n",
        "img = PIL.Image.open(fear_easy)\n",
        "response7 = vision_model.generate_content([\"What is the emotion expressed in the given picture?\", img], stream = True)"
      ],
      "metadata": {
        "id": "9sT87pQCVzLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response7.resolve()"
      ],
      "metadata": {
        "id": "JuM4HBRRWYtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response7.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "4qSrzwFJWahs",
        "outputId": "33356397-81db-4bd3-b5df-d1687a8fc65b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">  The emotion expressed in the given picture is fear."
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# case 8: Fear (Difficult)\n",
        "fear_diff = \"emotion_face_images/fear/739.jpg\"\n",
        "img = PIL.Image.open(fear_diff)\n",
        "response8 = vision_model.generate_content([\"What is the emotion expressed in the given picture?\", img], stream = True)"
      ],
      "metadata": {
        "id": "UCdJtTpiWcDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response8.resolve()"
      ],
      "metadata": {
        "id": "ZWNFlvIuWpOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response8.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "SHWpwbwwWq6_",
        "outputId": "a5968e87-0e32-4488-d4b6-648c26e31fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">  The emotion expressed in the given picture is sadness."
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation: can categorize easy images of fear but confuses it with other common negative emotions when more ambiguous."
      ],
      "metadata": {
        "id": "e_VE0ZSkWt9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask gemini to write code or use predefined tools for calculations instead of performing them on the fly"
      ],
      "metadata": {
        "id": "UvjWYKh9Wsn7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e92YWYRw0f_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WlMUL9ZrnD9a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}